{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvclkBoHuusvuQhddf60lg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galitneu/auto-eda-tool/blob/main/%D7%95%D7%A9%D7%90%D7%A8%D7%99%D7%95%D7%AA_%D7%97%D7%99%D7%A9%D7%95%D7%91_%D7%A2%D7%9D_%D7%90%D7%99%D7%A0%D7%A4%D7%9C%D7%A6%D7%99%D7%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0K-CEAxCUF0",
        "outputId": "cb45ceed-c28d-41dc-97db-96ddbf95385d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "מבצע סינון ראשוני לשמירת נתונים משנת 2000 ואילך...\n",
            "\n",
            "מבצע התאמה של מחירי המכירה לאינפלציה (לערכי 2012)...\n",
            "יוצר מאפייני זמן מתקדמים...\n",
            "מאפייני זמן נוצרו בהצלחה.\n",
            "\n",
            "מבצע הפרדת מגמה וחישוב שאריות...\n",
            "חישוב השאריות הושלם.\n",
            "\n",
            "מבצע הנדסת מאפיינים...\n",
            "\n",
            "מבצע הנדסת מאפיינים עם תיקון חכם ל-YearMade...\n",
            "מחשב שנת ייצור חציונית לכל דגם...\n",
            "מתקן 33186 רשומות עם YearMade=1000...\n",
            "התיקון הושלם.\n",
            "מטפל בערכים חסרים...\n",
            "מבצע תיקון חכם ל-MachineHoursCurrentMeter=0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-540504499.py:119: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
            "/tmp/ipython-input-540504499.py:132: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].fillna(global_median_hours, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "נוצר מאפיין אינטראקציה חדש: 'is_Year1000_and_ProblematicHydraulics'\n",
            "מטפל בערכים חסרים...\n",
            "ממיר עמודות קטגוריאליות למספרים...\n",
            "\n",
            "--- שלב 6: אימון מודל ראשוני על שאריות (2000-2010) ---\n",
            "\n",
            "--- ביצועי המודל הראשוני (אומן על 2000-2010) ---\n",
            "סט וולידציה (Validation Set - 2011):\n",
            "\tRMSE:  $9,670.11\n",
            "\tRMSLE: 0.2406\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- שלב 7: אימון מודל סופי על כל שאריות האימון (2000-2011) ---\n",
            "אימון המודל הסופי הושלם.\n",
            "\n",
            "--- ביצועי המודל הסופי (אומן על 2000-2011) ---\n",
            "סט וולידציה (Validation Set - 2011):\n",
            "\tRMSE:  $4,955.23\n",
            "\tRMSLE: 0.1363\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- שלב 0: ייבוא ספריות וחיבור לגוגל דרייב ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# חיבור סביבת העבודה לגוגל דרייב\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- שלב 1: הגדרת נתיבים, טעינת הנתונים ועיבוד ראשוני ---\n",
        "DRIVE_PATH = '/content/drive/MyDrive/KaggleProject/'\n",
        "try:\n",
        "    df_train_raw = pd.read_csv(f'{DRIVE_PATH}Train.csv', low_memory=False)\n",
        "    df_valid_raw = pd.read_csv(f'{DRIVE_PATH}Valid.csv', low_memory=False)\n",
        "except FileNotFoundError:\n",
        "    print(f\"שגיאה: ודא שהקבצים 'Train.csv' ו-'Valid.csv' נמצאים בתיקייה: {DRIVE_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# המרת תאריכים וסינון הנתונים לשנים 2000 ואילך\n",
        "print(\"מבצע סינון ראשוני לשמירת נתונים משנת 2000 ואילך...\")\n",
        "df_train_raw['saledate'] = pd.to_datetime(df_train_raw['saledate'])\n",
        "df_valid_raw['saledate'] = pd.to_datetime(df_valid_raw['saledate'])\n",
        "df_train_raw = df_train_raw[df_train_raw['saledate'].dt.year >= 2000].copy()\n",
        "df_valid_raw = df_valid_raw[df_valid_raw['saledate'].dt.year >= 2000].copy()\n",
        "\n",
        "# --- שלב 1.5: התאמת מחירים לאינפלציה ---\n",
        "print(\"\\nמבצע התאמה של מחירי המכירה לאינפלציה (לערכי 2012)...\")\n",
        "cpi_data_real = {\n",
        "    2000: 172.2, 2001: 177.1, 2002: 179.9, 2003: 184.0, 2004: 188.9, 2005: 195.3,\n",
        "    2006: 201.6, 2007: 207.3, 2008: 215.3, 2009: 214.5, 2010: 218.1, 2011: 224.9, 2012: 229.6\n",
        "}\n",
        "ADJUSTMENT_YEAR = 2012\n",
        "inflation_multiplier = {year: cpi_data_real[ADJUSTMENT_YEAR] / cpi for year, cpi in cpi_data_real.items()}\n",
        "df_train_raw['SalePrice_adj'] = df_train_raw.apply(\n",
        "    lambda row: row['SalePrice'] * inflation_multiplier.get(row['saledate'].year, 1), axis=1\n",
        ")\n",
        "# שמירת המחיר המקורי של סט האימון בצד\n",
        "train_original_prices = df_train_raw[['SalePrice', 'SalePrice_adj']].copy()\n",
        "\n",
        "# --- שלב 1.6: יצירת מאפייני זמן מתקדמים ---\n",
        "print(\"יוצר מאפייני זמן מתקדמים...\")\n",
        "df_train_raw['source'] = 'train'\n",
        "df_valid_raw['source'] = 'valid'\n",
        "df_combined_temp = pd.concat([df_train_raw.drop(['SalePrice', 'SalePrice_adj'], axis=1), df_valid_raw], ignore_index=True)\n",
        "\n",
        "df_combined_temp['saleYear'] = df_combined_temp['saledate'].dt.year\n",
        "df_combined_temp['saleMonth'] = df_combined_temp['saledate'].dt.month\n",
        "df_combined_temp['saleDay'] = df_combined_temp['saledate'].dt.day\n",
        "df_combined_temp['saleWeekOfYear'] = df_combined_temp['saledate'].dt.isocalendar().week.astype(int)\n",
        "df_combined_temp['saleDayOfWeek'] = df_combined_temp['saledate'].dt.dayofweek\n",
        "min_date = df_combined_temp['saledate'].min()\n",
        "df_combined_temp['DaysFromStart'] = (df_combined_temp['saledate'] - min_date).dt.days\n",
        "\n",
        "df_train_raw = df_combined_temp[df_combined_temp['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_valid_raw = df_combined_temp[df_combined_temp['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "df_train_raw = pd.concat([df_train_raw.reset_index(drop=True), train_original_prices.reset_index(drop=True)], axis=1)\n",
        "print(\"מאפייני זמן נוצרו בהצלחה.\")\n",
        "\n",
        "# --- שלב 1.7: פיצול הבעיה - אימון מודל מגמה וחישוב שאריות ---\n",
        "print(\"\\nמבצע הפרדת מגמה וחישוב שאריות...\")\n",
        "trend_model = LinearRegression()\n",
        "X_trend = df_train_raw[['DaysFromStart']]\n",
        "y_trend = df_train_raw['SalePrice_adj']\n",
        "trend_model.fit(X_trend, y_trend)\n",
        "df_train_raw['SalePrice_Trend'] = trend_model.predict(df_train_raw[['DaysFromStart']])\n",
        "df_valid_raw['SalePrice_Trend'] = trend_model.predict(df_valid_raw[['DaysFromStart']])\n",
        "df_train_raw['SalePrice_Residual'] = df_train_raw['SalePrice_adj'] - df_train_raw['SalePrice_Trend']\n",
        "print(\"חישוב השאריות הושלם.\")\n",
        "\n",
        "# --- שלב 2: איחוד קבצים לעיבוד אחיד ---\n",
        "train_labels_residual = df_train_raw['SalePrice_Residual'].copy()\n",
        "train_labels_adj_price = df_train_raw['SalePrice_adj'].copy()\n",
        "df_train_proc = df_train_raw.drop(['SalePrice', 'SalePrice_adj', 'SalePrice_Trend', 'SalePrice_Residual'], axis=1)\n",
        "df_train_proc['source'] = 'train'\n",
        "df_valid_proc = df_valid_raw.drop(['SalePrice_Trend'], axis=1)\n",
        "df_valid_proc['source'] = 'valid'\n",
        "df_combined = pd.concat([df_train_proc, df_valid_proc], ignore_index=True, sort=False)\n",
        "df_combined = df_combined.drop('saledate', axis=1)\n",
        "\n",
        "# ##################################################################\n",
        "# ######### שילוב הנדסת המאפיינים המקורית שלך עם התיקון #############\n",
        "# ##################################################################\n",
        "\n",
        "# --- שלב 3: הנדסת מאפיינים (Feature Engineering) ---\n",
        "print(\"\\nמבצע הנדסת מאפיינים...\")\n",
        "# --- שלב 3 (משודרג): הנדסת מאפיינים עם תיקון חכם ל-YearMade ---\n",
        "print(\"\\nמבצע הנדסת מאפיינים עם תיקון חכם ל-YearMade...\")\n",
        "\n",
        "# 1. חישוב שנת הייצור החציונית לכל דגם\n",
        "print(\"מחשב שנת ייצור חציונית לכל דגם...\")\n",
        "year_made_by_model = df_combined.groupby('fiModelDesc')['YearMade'].median()\n",
        "year_made_by_model = year_made_by_model.astype(int)\n",
        "\n",
        "# 2. זיהוי ותיקון השורות עם YearMade=1000\n",
        "rows_to_fix_idx = df_combined[df_combined['YearMade'] == 1000].index\n",
        "print(f\"מתקן {len(rows_to_fix_idx)} רשומות עם YearMade=1000...\")\n",
        "imputed_years = df_combined.loc[rows_to_fix_idx, 'fiModelDesc'].map(year_made_by_model)\n",
        "global_median_year = df_combined[df_combined['YearMade'] != 1000]['YearMade'].median()\n",
        "imputed_years = imputed_years.fillna(global_median_year)\n",
        "df_combined.loc[rows_to_fix_idx, 'YearMade'] = imputed_years.values\n",
        "print(\"התיקון הושלם.\")\n",
        "\n",
        "# 3. עכשיו, אחרי שהכל תוקן, מחשבים את גיל המכונה\n",
        "df_combined['machineAge'] = df_combined['saleYear'] - df_combined['YearMade']\n",
        "\n",
        "\n",
        "# --- שלב 4 (משודרג): טיפול בערכים חסרים עם תיקון חכם ל-MachineHoursCurrentMeter ---\n",
        "print(\"מטפל בערכים חסרים...\")\n",
        "\n",
        "# --- טיפול חכם ב-MachineHoursCurrentMeter ---\n",
        "print(\"מבצע תיקון חכם ל-MachineHoursCurrentMeter=0...\")\n",
        "# יצירת עמודת _is_missing לפני השינויים. היא תתפוס גם NaN וגם 0.\n",
        "df_combined['MachineHoursCurrentMeter_is_missing'] = df_combined['MachineHoursCurrentMeter'].isnull() | (df_combined['MachineHoursCurrentMeter'] == 0)\n",
        "\n",
        "# החלפת 0 ב-NaN כדי שנוכל למלא אותו\n",
        "df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
        "\n",
        "# חישוב חציון שעות עבודה לפי דגם\n",
        "hours_by_model = df_combined.groupby('fiModelDesc')['MachineHoursCurrentMeter'].median()\n",
        "\n",
        "# מילוי הערכים החסרים באמצעות החציון של הדגם המתאים\n",
        "# נשתמש ב-transform כדי לשמור על האינדקס המקורי של df_combined\n",
        "imputed_hours = df_combined.groupby('fiModelDesc')['MachineHoursCurrentMeter'].transform(lambda x: x.fillna(x.median()))\n",
        "df_combined['MachineHoursCurrentMeter'] = imputed_hours\n",
        "\n",
        "# אם עדיין נשארו ערכים חסרים (לדגמים נדירים), נמלא בחציון הכללי\n",
        "if df_combined['MachineHoursCurrentMeter'].isnull().sum() > 0:\n",
        "    global_median_hours = df_combined['MachineHoursCurrentMeter'].median()\n",
        "    df_combined['MachineHoursCurrentMeter'].fillna(global_median_hours, inplace=True)\n",
        "\n",
        "df_combined['fiProductClassDesc'] = df_combined['fiProductClassDesc'].fillna('')\n",
        "keywords_to_extract = ['excavator', 'dozer', 'loader', 'crawler', 'wheel', 'track']\n",
        "for keyword in keywords_to_extract:\n",
        "    df_combined[f'is_{keyword}'] = df_combined['fiProductClassDesc'].str.contains(keyword, case=False).astype(int)\n",
        "\n",
        "df_combined['is_YearMade_1000'] = (df_combined['YearMade'] == 1000).astype(int)\n",
        "df_combined['is_Hours_Zero'] = (df_combined['MachineHoursCurrentMeter'] == 0).astype(int)\n",
        "df_combined['is_ProductGroup_5'] = (df_combined['ProductGroup'] == 5).astype(int)\n",
        "df_combined['is_ProductGroup_2'] = (df_combined['ProductGroup'] == 2).astype(int)\n",
        "\n",
        "# הגדרת הקטגוריות הבעייתיות שמצאנו בניתוח\n",
        "problematic_hydraulics = [0, 11]\n",
        "\n",
        "# יצירת מאפיין האינטראקציה החדש\n",
        "df_combined['is_Year1000_and_ProblematicHydraulics'] = (\n",
        "    (df_combined['YearMade'] == 1000) &\n",
        "    (df_combined['Hydraulics'].isin(problematic_hydraulics))\n",
        ").astype(int)\n",
        "\n",
        "print(\"נוצר מאפיין אינטראקציה חדש: 'is_Year1000_and_ProblematicHydraulics'\")\n",
        "# --- שלב 4: טיפול בערכים חסרים (Missing Values) ---\n",
        "print(\"מטפל בערכים חסרים...\")\n",
        "# טיפול בערכים מספריים חסרים\n",
        "numeric_cols_missing = ['MachineHoursCurrentMeter', 'auctioneerID']\n",
        "for col in numeric_cols_missing:\n",
        "    if df_combined[col].isnull().sum() > 0:\n",
        "        df_combined[col + '_is_missing'] = df_combined[col].isnull()\n",
        "        median_val = df_combined[col].median()\n",
        "        df_combined[col] = df_combined[col].fillna(median_val)\n",
        "\n",
        "# טיפול בערכים קטגוריאליים חסרים (עם התיקון שהופך אותו לרובוסטי)\n",
        "for col_name in df_combined.columns:\n",
        "    if pd.api.types.is_object_dtype(df_combined[col_name]):\n",
        "        df_combined[col_name] = df_combined[col_name].fillna('missing')\n",
        "\n",
        "# --- שלב 5: המרת עמודות קטגוריאליות למספרים ---\n",
        "print(\"ממיר עמודות קטגוריאליות למספרים...\")\n",
        "# עכשיו הלוגיקה המקורית שלך תעבוד בבטחה\n",
        "source_col = df_combined['source'] # שמירת עמודת המקור בצד\n",
        "df_combined = df_combined.drop('source', axis=1)\n",
        "cols_to_drop = []\n",
        "\n",
        "for col_name in df_combined.columns:\n",
        "    if pd.api.types.is_object_dtype(df_combined[col_name]):\n",
        "        num_unique_values = df_combined[col_name].nunique()\n",
        "        # לוגיקת One-Hot Encoding לעמודות עם מעט ערכים\n",
        "        if num_unique_values <= 5:\n",
        "            dummies = pd.get_dummies(df_combined[col_name], prefix=col_name)\n",
        "            df_combined = pd.concat([df_combined, dummies], axis=1)\n",
        "            cols_to_drop.append(col_name)\n",
        "        # לוגיקת Label Encoding לעמודות עם הרבה ערכים\n",
        "        else:\n",
        "            df_combined[col_name] = pd.Categorical(df_combined[col_name]).codes\n",
        "\n",
        "df_combined = df_combined.drop(columns=cols_to_drop)\n",
        "df_combined['source'] = source_col # החזרת עמודת המקור\n",
        "\n",
        "# --- פונקציות עזר לחישוב מדדי שגיאה ---\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "def rmsle(y_true, y_pred):\n",
        "    y_pred_safe = np.maximum(y_pred, 1)\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred_safe))\n",
        "\n",
        "# --- שלב 6: אימון ראשוני והערכה מקומית ---\n",
        "df_train_processed = df_combined[df_combined['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_valid_processed = df_combined[df_combined['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "\n",
        "df_train_processed['SalePrice_Residual'] = train_labels_residual.values\n",
        "df_train_processed['SalePrice_adj'] = train_labels_adj_price.values\n",
        "df_train_processed['SalePrice_Trend'] = df_train_raw['SalePrice_Trend'].values\n",
        "\n",
        "val_year = 2011\n",
        "train_time_split = df_train_processed[df_train_processed['saleYear'] <= val_year - 1]\n",
        "val_time_split = df_train_processed[df_train_processed['saleYear'] == val_year]\n",
        "\n",
        "X_train_time = train_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'SalePrice_Trend'], axis=1)\n",
        "y_train_time_residual = train_time_split['SalePrice_Residual']\n",
        "X_val_time = val_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'SalePrice_Trend'], axis=1)\n",
        "y_val_time_actual_price = val_time_split['SalePrice_adj']\n",
        "val_time_trend = val_time_split['SalePrice_Trend']\n",
        "\n",
        "# ודא שסדר העמודות זהה בין סט האימון והבדיקה\n",
        "X_val_time = X_val_time[X_train_time.columns]\n",
        "\n",
        "print(\"\\n--- שלב 6: אימון מודל ראשוני על שאריות (2000-2010) ---\")\n",
        "initial_model = RandomForestRegressor(n_jobs=-1, random_state=42, n_estimators=150, min_samples_split=5, min_samples_leaf=4, max_features=0.5, max_depth=30)\n",
        "initial_model.fit(X_train_time, y_train_time_residual)\n",
        "\n",
        "print(\"\\n--- ביצועי המודל הראשוני (אומן על 2000-2010) ---\")\n",
        "initial_val_preds_residual = initial_model.predict(X_val_time)\n",
        "initial_val_preds_full_price = val_time_trend + initial_val_preds_residual\n",
        "initial_val_rmse = rmse(y_val_time_actual_price, initial_val_preds_full_price)\n",
        "initial_val_rmsle = rmsle(y_val_time_actual_price, initial_val_preds_full_price)\n",
        "\n",
        "print(f\"סט וולידציה (Validation Set - 2011):\")\n",
        "print(f\"\\tRMSE:  ${initial_val_rmse:,.2f}\")\n",
        "print(f\"\\tRMSLE: {initial_val_rmsle:.4f}\\n\")\n",
        "\n",
        "# --- שלב 7: אימון מודל סופי והערכה סופית ---\n",
        "print(\"=\"*50)\n",
        "print(\"\\n--- שלב 7: אימון מודל סופי על כל שאריות האימון (2000-2011) ---\")\n",
        "\n",
        "X_full_train = df_train_processed.drop(['SalePrice_Residual', 'SalePrice_adj', 'SalePrice_Trend'], axis=1)\n",
        "y_full_train_residual = df_train_processed['SalePrice_Residual']\n",
        "\n",
        "final_model = RandomForestRegressor(n_jobs=-1, random_state=42, n_estimators=150, min_samples_split=5, min_samples_leaf=4, max_features=0.5, max_depth=30)\n",
        "final_model.fit(X_full_train, y_full_train_residual)\n",
        "print(\"אימון המודל הסופי הושלם.\")\n",
        "\n",
        "print(\"\\n--- ביצועי המודל הסופי (אומן על 2000-2011) ---\")\n",
        "final_val_preds_residual = final_model.predict(X_val_time)\n",
        "final_val_preds_full_price = val_time_trend + final_val_preds_residual\n",
        "final_val_rmse = rmse(y_val_time_actual_price, final_val_preds_full_price)\n",
        "final_val_rmsle = rmsle(y_val_time_actual_price, final_val_preds_full_price)\n",
        "\n",
        "print(f\"סט וולידציה (Validation Set - 2011):\")\n",
        "print(f\"\\tRMSE:  ${final_val_rmse:,.2f}\")\n",
        "print(f\"\\tRMSLE: {final_val_rmsle:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- שלב 8: יצירת קובץ הגשה סופי עם מודל השאריות ---\n",
        "print(\"=\"*50)\n",
        "print(\"\\n--- שלב 8: יצירת קובץ הגשה באמצעות המודל הסופי (מודל השאריות) ---\")\n",
        "\n",
        "# 1. התאמת עמודות בין סט האימון לסט הוולידציה (הבדיקה)\n",
        "# שלב זה חיוני כדי להבטיח שלסט הוולידציה יש בדיוק את אותן עמודות כמו לסט שהמודל אומן עליו\n",
        "train_cols = X_full_train.columns\n",
        "valid_cols_to_align = df_valid_processed[train_cols]\n",
        "\n",
        "\n",
        "# 2. חיזוי דו-שלבי\n",
        "# 2.1: חיזוי השאריות באמצעות המודל המורכב\n",
        "print(\"שלב 1/3: מבצע חיזוי לשאריות...\")\n",
        "final_residuals_pred = final_model.predict(valid_cols_to_align)\n",
        "\n",
        "# 2.2: שליפת ערכי המגמה שכבר חישבנו עבור סט הוולידציה\n",
        "print(\"שלב 2/3: משחזר את ערכי המגמה...\")\n",
        "final_trend_values = df_valid_raw['SalePrice_Trend'].values\n",
        "\n",
        "# 3. שחזור המחיר הסופי\n",
        "# החיזוי הסופי הוא הסכום של המגמה החזויה והשארית החזויה\n",
        "print(\"שלב 3/3: מחבר את המגמה והשאריות ליצירת חיזוי סופי...\")\n",
        "final_price_pred = final_trend_values + final_residuals_pred\n",
        "\n",
        "\n",
        "# 4. ליטוש אחרון: קביעת רצפה למניעת מחירים שליליים\n",
        "# כפי שדיברנו, נגדיר מחיר מינימום של 1000$\n",
        "final_price_pred_floored = np.maximum(final_price_pred, 1000)\n",
        "\n",
        "\n",
        "# 5. יצירת קובץ ההגשה ושמירתו\n",
        "df_submission = pd.DataFrame({\n",
        "    'SalesID': df_valid_raw['SalesID'],\n",
        "    'SalePrice': final_price_pred_floored\n",
        "})\n",
        "\n",
        "submission_filename = f'{DRIVE_PATH}submission_residuals_model.csv'\n",
        "df_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nקובץ ההגשה '{submission_filename}' נשמר בהצלחה!\")\n",
        "print(\"5 השורות הראשונות בקובץ ההגשה:\")\n",
        "print(df_submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2izIOnSrwl",
        "outputId": "e59c00d9-b563-42e1-d429-cf58720b562e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\n",
            "--- שלב 8: יצירת קובץ הגשה באמצעות המודל הסופי (מודל השאריות) ---\n",
            "שלב 1/3: מבצע חיזוי לשאריות...\n",
            "שלב 2/3: משחזר את ערכי המגמה...\n",
            "שלב 3/3: מחבר את המגמה והשאריות ליצירת חיזוי סופי...\n",
            "\n",
            "קובץ ההגשה '/content/drive/MyDrive/KaggleProject/submission_residuals_model.csv' נשמר בהצלחה!\n",
            "5 השורות הראשונות בקובץ ההגשה:\n",
            "        SalesID     SalePrice\n",
            "313947  1222837  55456.236620\n",
            "313948  1222839  72420.602852\n",
            "313949  1222841  34047.907885\n",
            "313950  1222843  17541.454588\n",
            "313951  1222845  42399.766207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# הרץ את הקוד הזה אחרי שלב 6 (אימון המודל הראשוני)\n",
        "print(\"\\n--- מנתח את השגיאות הגדולות ביותר של המודל ---\")\n",
        "\n",
        "# חישוב השגיאה המוחלטת\n",
        "val_time_split['predictions'] = initial_val_preds_full_price\n",
        "val_time_split['error'] = abs(val_time_split['SalePrice_adj'] - val_time_split['predictions'])\n",
        "\n",
        "# מיון לפי השגיאה הגבוהה ביותר\n",
        "worst_predictions = val_time_split.sort_values('error', ascending=False)\n",
        "\n",
        "# הצגת 10 הטעויות הגדולות ביותר\n",
        "print(\"10 החיזויים עם השגיאה הגבוהה ביותר:\")\n",
        "print(worst_predictions[['SalesID', 'SalePrice_adj', 'predictions', 'error', 'ProductGroupDesc', 'YearMade', 'MachineHoursCurrentMeter']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF5Qs50uYMHL",
        "outputId": "3cf00577-fd51-4899-c977-11ca4139631c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- מנתח את השגיאות הגדולות ביותר של המודל ---\n",
            "10 החיזויים עם השגיאה הגבוהה ביותר:\n",
            "        SalesID  SalePrice_adj   predictions         error  ProductGroupDesc  \\\n",
            "51489   1350808  107194.308582  27661.261602  79533.046980                 3   \n",
            "276214  2529117   91880.835927  14378.758711  77502.077216                 3   \n",
            "23033   1219396  122507.781236  46093.892095  76413.889142                 4   \n",
            "306769  6265877    9698.532681  78146.856202  68448.323521                 4   \n",
            "306766  6265869  127612.272121  60736.986051  66875.286070                 4   \n",
            "307929  6272435  125060.026679  59018.503670  66041.523009                 4   \n",
            "297595  4316103  109746.554024  43861.564332  65884.989692                 3   \n",
            "279075  2558425  107194.308582  42101.533604  65092.774977                 4   \n",
            "307907  6272347  127612.272121  62910.383173  64701.888948                 4   \n",
            "286890  2700236  103110.715874  38720.346175  64390.369699                 3   \n",
            "\n",
            "        YearMade  MachineHoursCurrentMeter  \n",
            "51489       1999                    6706.5  \n",
            "276214      1988                    1941.0  \n",
            "23033       1992                    4618.0  \n",
            "306769      1996                   14393.0  \n",
            "306766      1996                   14393.0  \n",
            "307929      2004                    5244.0  \n",
            "297595      2002                    4474.0  \n",
            "279075      1980                    4637.0  \n",
            "307907      2004                    3453.0  \n",
            "286890      1998                    9874.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4119580116.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_time_split['predictions'] = initial_val_preds_full_price\n",
            "/tmp/ipython-input-4119580116.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_time_split['error'] = abs(val_time_split['SalePrice_adj'] - val_time_split['predictions'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- שלב 0: ייבוא ספריות נוספות ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ######################################################################\n",
        "# ### שלב 7 (חדש): אימון מודל דו-שלבי ###\n",
        "# ######################################################################\n",
        "print(\"=\"*50)\n",
        "print(\"\\n--- שלב 7: מתחיל אימון מודל דו-שלבי (ממיין + מומחים) ---\")\n",
        "\n",
        "# 1. הגדרת סף למכונה \"יקרה\"\n",
        "# נשתמש באחוזון ה-75 של המחירים המתוקננים כסף\n",
        "price_threshold = df_train_processed['SalePrice_adj'].quantile(0.75)\n",
        "print(f\"סף המחיר למכונה 'יקרה' נקבע על: ${price_threshold:,.2f}\")\n",
        "\n",
        "# יצירת משתנה מטרה חדש לסיווג\n",
        "df_train_processed['is_expensive'] = (df_train_processed['SalePrice_adj'] > price_threshold).astype(int)\n",
        "\n",
        "# 2. הכנת נתונים לאימון\n",
        "X_full_train = df_train_processed.drop(['SalePrice_Residual', 'SalePrice_adj', 'is_expensive'], axis=1)\n",
        "y_full_train_residual = df_train_processed['SalePrice_Residual']\n",
        "y_full_train_classifier = df_train_processed['is_expensive']\n",
        "\n",
        "\n",
        "# 3. אימון הממיין (Classifier)\n",
        "print(\"\\nמאמן את המודל הממיין...\")\n",
        "classifier_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15)\n",
        "classifier_model.fit(X_full_train, y_full_train_classifier)\n",
        "print(\"אימון הממיין הושלם.\")\n",
        "\n",
        "\n",
        "# 4. פיצול הנתונים ל\"יקר\" ו\"לא יקר\"\n",
        "expensive_idx = df_train_processed[df_train_processed['is_expensive'] == 1].index\n",
        "not_expensive_idx = df_train_processed[df_train_processed['is_expensive'] == 0].index\n",
        "\n",
        "X_train_expensive = X_full_train.loc[expensive_idx]\n",
        "y_train_expensive = y_full_train_residual.loc[expensive_idx]\n",
        "\n",
        "X_train_not_expensive = X_full_train.loc[not_expensive_idx]\n",
        "y_train_not_expensive = y_full_train_residual.loc[not_expensive_idx]\n",
        "\n",
        "\n",
        "# 5. אימון המומחים (Regressors)\n",
        "# נשתמש בפרמטרים המכוילים שלך או בפרמטרים טובים אחרים\n",
        "params = {'n_jobs': -1, 'random_state': 42, 'n_estimators': 400, 'min_samples_leaf': 1, 'min_samples_split': 2, 'max_features': 0.5}\n",
        "\n",
        "print(\"\\nמאמן את המומחה למכונות יקרות...\")\n",
        "regressor_expensive = RandomForestRegressor(**params)\n",
        "regressor_expensive.fit(X_train_expensive, y_train_expensive)\n",
        "print(\"אימון המומחה למכונות יקרות הושלם.\")\n",
        "\n",
        "print(\"\\nמאמן את המומחה למכונות רגילות...\")\n",
        "regressor_not_expensive = RandomForestRegressor(**params)\n",
        "regressor_not_expensive.fit(X_train_not_expensive, y_train_not_expensive)\n",
        "print(\"אימון המומחה למכונות רגילות הושלם.\")\n",
        "\n",
        "\n",
        "# ######################################################################\n",
        "# ### שלב 8 (חדש): יצירת הגשה עם המודל הדו-שלבי ###\n",
        "# ######################################################################\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- שלב 8: יוצר קובץ הגשה עם המודל הדו-שלבי ---\")\n",
        "\n",
        "# 1. התאמת עמודות\n",
        "df_valid_processed_aligned = df_valid_processed[X_full_train.columns]\n",
        "\n",
        "# 2. שימוש בממיין כדי להחליט לאיזה מומחה לשלוח כל מכונה\n",
        "print(\"שלב 1/3: מסווג את נתוני המבחן ל'יקר' ו'לא יקר'...\")\n",
        "valid_classifications = classifier_model.predict(df_valid_processed_aligned)\n",
        "\n",
        "# 3. חיזוי עם המומחה המתאים\n",
        "print(\"שלב 2/3: מריץ חיזוי עם המומחים המתאימים...\")\n",
        "# יצירת מערך ריק לאחסון החיזויים\n",
        "final_residuals_pred = np.zeros(len(df_valid_processed_aligned))\n",
        "\n",
        "# זיהוי האינדקסים של כל קבוצה\n",
        "expensive_mask = (valid_classifications == 1)\n",
        "not_expensive_mask = (valid_classifications == 0)\n",
        "\n",
        "# חיזוי לכל קבוצה בנפרד\n",
        "final_residuals_pred[expensive_mask] = regressor_expensive.predict(df_valid_processed_aligned[expensive_mask])\n",
        "final_residuals_pred[not_expensive_mask] = regressor_not_expensive.predict(df_valid_processed_aligned[not_expensive_mask])\n",
        "\n",
        "# 4. שחזור המחיר הסופי (כמו קודם)\n",
        "print(\"שלב 3/3: משחזר את המחיר הסופי...\")\n",
        "final_trend_values = df_valid_raw['SalePrice_Trend'].values\n",
        "final_price_pred = final_trend_values + final_residuals_pred\n",
        "final_price_pred_floored = np.maximum(final_price_pred, 1000)\n",
        "\n",
        "# 5. יצירת ושמירת הקובץ\n",
        "df_submission = pd.DataFrame({'SalesID': df_valid_raw['SalesID'], 'SalePrice': final_price_pred_floored})\n",
        "submission_filename = f'{DRIVE_PATH}submission_TwoStage_model.csv'\n",
        "df_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nקובץ ההגשה '{submission_filename}' נשמר בהצלחה!\")\n",
        "print(\"5 השורות הראשונות בקובץ ההגשה:\")\n",
        "print(df_submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "mFZJAjfZwOKF",
        "outputId": "5deff866-8d21-482b-937b-1823ec79a1ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\n",
            "--- שלב 7: מתחיל אימון מודל דו-שלבי (ממיין + מומחים) ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_train_processed' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1590571191.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 1. הגדרת סף למכונה \"יקרה\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# נשתמש באחוזון ה-75 של המחירים המתוקננים כסף\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprice_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice_adj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"סף המחיר למכונה 'יקרה' נקבע על: ${price_threshold:,.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train_processed' is not defined"
          ]
        }
      ]
    }
  ]
}