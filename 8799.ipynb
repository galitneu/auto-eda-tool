{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwhsEc2iokVWqjKJXOtFXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galitneu/auto-eda-tool/blob/main/8799.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCGR13MYiEHW",
        "outputId": "45b62d0f-055d-4012-aad1-51aab1d4ebf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- שלב 1: טוען נתונים ---\n",
            "Mounted at /content/drive\n",
            "נתונים נטענו בהצלחה.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:113: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:118: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].fillna(df_combined['MachineHoursCurrentMeter'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "---  הערכת ביצועים על סט וולידציה עונתי (ינואר-אפריל 2011) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:178: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:179: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_val_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "מאמן מודל וולידציה (על נתוני 2000-2010)...\n",
            "\n",
            "--- ביצועי המודל על סט הוולידציה העונתי ---\n",
            "סט וולידציה (Validation Set - ינואר-אפריל 2011):\n",
            "\tRMSE:  $8,672.77\n",
            "\tRMSLE: 0.2207\n",
            "\n",
            "\n",
            "==================================================\n",
            "---  מאמן מודל סופי עם הפרמטרים ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:239: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_full_train['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:242: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_valid_processed_aligned['State_Median_Price'].fillna(global_median_price, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "אימון המודל הסופי הושלם!\n",
            "\n",
            "קובץ ההגשה '/content/drive/MyDrive/KaggleProject/submission_Final_Winning_Model_v4.csv' נשמר בהצלחה!\n",
            "5 השורות הראשונות בקובץ ההגשה:\n",
            "        SalesID     SalePrice\n",
            "313947  1222837  55901.228088\n",
            "313948  1222839  79930.670615\n",
            "313949  1222841  33336.578450\n",
            "313950  1222843  16935.470268\n",
            "313951  1222845  40982.306060\n"
          ]
        }
      ],
      "source": [
        "# --- שלב 0: ייבוא כל הספריות הנדרשות ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from google.colab import drive\n",
        "\n",
        "# --- שלב 1: הגדרות וטעינת נתונים ---\n",
        "print(\"--- שלב 1: טוען נתונים ---\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_PATH = '/content/drive/MyDrive/KaggleProject/'\n",
        "\n",
        "# םתיחת הקבצים לאימון וניבוי\n",
        "try:\n",
        "    df_train_raw = pd.read_csv(f'{DRIVE_PATH}Train.csv', low_memory=False, parse_dates=['saledate'])\n",
        "    df_valid_raw = pd.read_csv(f'{DRIVE_PATH}Valid.csv', low_memory=False, parse_dates=['saledate'])\n",
        "    print(\"נתונים נטענו בהצלחה.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"שגיאה: ודא שהקבצים 'Train.csv' ו-'Valid.csv' נמצאים בתיקייה: {DRIVE_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# ---  עיבוד נתונים והנדסת מאפיינים ---\n",
        "\n",
        "# סינון לשנים 2000 ומעלה בגלל שהכלים השתנו במשך השנים ומתחת לשנים האלה זה רעש\n",
        "df_train_raw = df_train_raw[df_train_raw['saledate'].dt.year >= 2000].copy()\n",
        "df_valid_raw = df_valid_raw[df_valid_raw['saledate'].dt.year >= 2000].copy()\n",
        "\n",
        "#תיקונים המחירים לשנת 2012 בגלל אינפלציה\n",
        "cpi_data_real = {\n",
        "    2000: 172.2, 2001: 177.1, 2002: 179.9, 2003: 184.0, 2004: 188.9, 2005: 195.3,\n",
        "    2006: 201.6, 2007: 207.3, 2008: 215.3, 2009: 214.5, 2010: 218.1, 2011: 224.9, 2012: 229.6\n",
        "}\n",
        "ADJUSTMENT_YEAR = 2012\n",
        "inflation_multiplier = {year: cpi_data_real[ADJUSTMENT_YEAR] / cpi for year, cpi in cpi_data_real.items()}\n",
        "\n",
        "#יצירת עמודה של מחירים מתוקנים\n",
        "df_train_raw['SalePrice_adj'] = df_train_raw.apply(lambda row: row['SalePrice'] * inflation_multiplier.get(row['saledate'].year, 1), axis=1)\n",
        "train_original_prices = df_train_raw[['SalePrice', 'SalePrice_adj']].copy()\n",
        "\n",
        "#יצירת עמודה מבדילה בין בנתונים לפני חיבור שלהם יחד\n",
        "df_train_raw['source'] = 'train'\n",
        "df_valid_raw['source'] = 'valid'\n",
        "df_combined_temp = pd.concat([df_train_raw.drop(['SalePrice', 'SalePrice_adj'], axis=1), df_valid_raw], ignore_index=True)\n",
        "\n",
        "#חיפוש אחר תאריך הקטן ביותר כדי למצוא את מספר הימים שעברו עבר כל  מכירה\n",
        "min_date = df_combined_temp['saledate'].min()\n",
        "#פיצול תאריך המכירה לחלקים חשובים כמו שנה, חודש, יום בתוך השנה, ויום מאז המכירה הישנה ביותר\n",
        "for df in [df_combined_temp]:\n",
        "    df['saleYear'] = df['saledate'].dt.year\n",
        "    df['saleMonth'] = df['saledate'].dt.month\n",
        "    df['DayOfYear'] = df['saledate'].dt.dayofyear\n",
        "    df['DaysFromStart'] = (df['saledate'] - min_date).dt.days\n",
        "\n",
        "#פיצול לשני דאטאסטים של אימון וניבוי\n",
        "df_train_raw = df_combined_temp[df_combined_temp['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_valid_raw = df_combined_temp[df_combined_temp['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "df_train_raw = pd.concat([df_train_raw.reset_index(drop=True), train_original_prices.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# 2.2 חישוב מגמה ושאריות עם שני מודלים עונתיים\n",
        "#פיצול הנתונים של האימון לחודשים ינואר-אפריל וכל השאר\n",
        "early_season_train_df = df_train_raw[df_train_raw['saleMonth'].isin([1, 2, 3, 4])].copy()\n",
        "rest_of_year_train_df = df_train_raw[~df_train_raw['saleMonth'].isin([1, 2, 3, 4])].copy()\n",
        "\n",
        "#יצירת מודל רגרסיה לכל אחד מחלקי האימון\n",
        "trend_model_early = LinearRegression()\n",
        "trend_model_early.fit(early_season_train_df[['DaysFromStart']], early_season_train_df['SalePrice_adj'])\n",
        "trend_model_rest = LinearRegression()\n",
        "trend_model_rest.fit(rest_of_year_train_df[['DaysFromStart']], rest_of_year_train_df['SalePrice_adj'])\n",
        "\n",
        "#הגדרת פונצירה עבור חישוב המחיר שהיה אמור להיות על פי הרגרסיה\n",
        "def predict_seasonal_trend(df):\n",
        "    early_mask = df['saleMonth'].isin([1, 2, 3, 4])\n",
        "    predictions = pd.Series(index=df.index, dtype=float)\n",
        "    if early_mask.sum() > 0:\n",
        "        predictions.loc[early_mask] = trend_model_early.predict(df.loc[early_mask, ['DaysFromStart']])\n",
        "    if (~early_mask).sum() > 0:\n",
        "        predictions.loc[~early_mask] = trend_model_rest.predict(df.loc[~early_mask, ['DaysFromStart']])\n",
        "    return predictions\n",
        "\n",
        "#עבור כל שורה - חישוב המחיר שהיה אמור להיות\n",
        "df_train_raw['SalePrice_Trend'] = predict_seasonal_trend(df_train_raw)\n",
        "df_valid_raw['SalePrice_Trend'] = predict_seasonal_trend(df_valid_raw)\n",
        "#חישוב הפער שבין המחיר שהיה אעמור להיות לבין המחיר בפועל כדי שעליו יתאמן המודל. זה רק עבור שנים 2000-2010\n",
        "df_train_raw['SalePrice_Residual'] = df_train_raw['SalePrice_adj'] - df_train_raw['SalePrice_Trend']\n",
        "\n",
        "# 2.3 איחוד לעיבוד סופי\n",
        "train_labels_residual = df_train_raw['SalePrice_Residual'].copy()\n",
        "df_train_proc = df_train_raw.drop(['SalePrice', 'SalePrice_adj', 'SalePrice_Trend', 'SalePrice_Residual', 'saledate', 'SalesID', 'MachineID'], axis=1)\n",
        "df_train_proc['source'] = 'train'\n",
        "df_valid_proc = df_valid_raw.drop(['SalePrice_Trend', 'saledate', 'SalesID', 'MachineID'], axis=1)\n",
        "df_valid_proc['source'] = 'valid'\n",
        "df_combined = pd.concat([df_train_proc, df_valid_proc], ignore_index=True, sort=False)\n",
        "\n",
        "# ---  הנדסת מאפיינים ועיבוד נתונים מאוחד  ---\n",
        "\n",
        "#הרמת דגל עבור שדות של שנת יצור לא תקינים\n",
        "df_combined['is_YearMade_1000'] = (df_combined['YearMade'] == 1000).astype(int)\n",
        "\n",
        "# תיקון לשדות של שנת יצור שהם 1000\n",
        "year_made_by_model = df_combined.groupby('fiModelDesc')['YearMade'].median().astype(int)\n",
        "rows_to_fix_idx = df_combined[df_combined['YearMade'] == 1000].index\n",
        "#בכנסת גיל חציוני של המודל הספציפי\n",
        "imputed_years = df_combined.loc[rows_to_fix_idx, 'fiModelDesc'].map(year_made_by_model)\n",
        "global_median_year = df_combined.loc[df_combined['YearMade'] != 1000, 'YearMade'].median()\n",
        "#הכנסת\n",
        "imputed_years = imputed_years.fillna(global_median_year)\n",
        "df_combined.loc[rows_to_fix_idx, 'YearMade'] = imputed_years.values\n",
        "#חישוב גיל המכונה במכירה\n",
        "df_combined['machineAge'] = df_combined['saleYear'] - df_combined['YearMade']\n",
        "\n",
        "#הרמת דגל לעמודת שעות עבודה לא תקנית\n",
        "df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
        "#חישוב חציון של שעות עבודה למודל הספציפי\n",
        "imputed_hours = df_combined.groupby('fiModelDesc')['MachineHoursCurrentMeter'].transform(lambda x: x.fillna(x.median()))\n",
        "df_combined['MachineHoursCurrentMeter'] = imputed_hours\n",
        "if df_combined['MachineHoursCurrentMeter'].isnull().sum() > 0:\n",
        "    df_combined['MachineHoursCurrentMeter'].fillna(df_combined['MachineHoursCurrentMeter'].median(), inplace=True)\n",
        "\n",
        "# טיפול ב-auctioneerID אן ריק אז מקבל  חציון\n",
        "if df_combined['auctioneerID'].isnull().sum() > 0:\n",
        "    df_combined['auctioneerID_is_missing'] = df_combined['auctioneerID'].isnull()\n",
        "    df_combined['auctioneerID'] = df_combined['auctioneerID'].fillna(df_combined['auctioneerID'].median())\n",
        "\n",
        "# --- הוספת מאפייני Ripper ו-Enclosure\n",
        "df_combined['Ripper_is_missing'] = df_combined['Ripper'].isnull().astype(int)\n",
        "ripper_types = ['Yes', 'Multi Shank', 'Single Shank']\n",
        "df_combined['has_Ripper'] = df_combined['Ripper'].isin(ripper_types).astype(int)\n",
        "enclosure_mode = df_combined['Enclosure'].mode()[0]\n",
        "df_combined['Enclosure_Type'] = df_combined['Enclosure'].fillna(enclosure_mode).astype('category').cat.codes\n",
        "df_combined.drop(['Ripper', 'Enclosure'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "df_combined['fiProductClassDesc'] = df_combined['fiProductClassDesc'].fillna('')\n",
        "keywords_to_extract = ['excavator', 'dozer', 'loader', 'crawler', 'wheel', 'track']\n",
        "for keyword in keywords_to_extract:\n",
        "    df_combined[f'is_{keyword}'] = df_combined['fiProductClassDesc'].str.contains(keyword, case=False).astype(int)\n",
        "df_combined['is_Hours_Zero'] = (df_combined['MachineHoursCurrentMeter'] == 0).astype(int)\n",
        "df_combined['is_ProductGroup_5'] = (df_combined['ProductGroup'] == 5).astype(int)\n",
        "df_combined['is_ProductGroup_2'] = (df_combined['ProductGroup'] == 2).astype(int)\n",
        "\n",
        "# המרת שאר עמודות הטקסט לקודים מספריים\n",
        "source_col = df_combined['source']\n",
        "df_combined = df_combined.drop('source', axis=1)\n",
        "for col_name in df_combined.columns:\n",
        "    if pd.api.types.is_object_dtype(df_combined[col_name]):\n",
        "        df_combined[col_name] = df_combined[col_name].fillna('missing').astype('category').cat.codes\n",
        "df_combined['source'] = source_col\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"---  הערכת ביצועים על סט וולידציה עונתי (ינואר-אפריל 2011) ---\")\n",
        "\n",
        "#  הכנת הנתונים לפיצול\n",
        "df_train_processed = df_combined[df_combined['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_train_processed['SalePrice_Residual'] = train_labels_residual.values\n",
        "df_train_processed['SalePrice_adj'] = df_train_raw['SalePrice_adj'].values\n",
        "df_train_processed['saledate'] = df_train_raw['saledate']\n",
        "\n",
        "#  פיצול עונתי\n",
        "train_time_split = df_train_processed[df_train_processed['saledate'] < '2011-01-01'].copy()\n",
        "validation_mask = (df_train_processed['saledate'] >= '2011-01-01') & (df_train_processed['saledate'] < '2011-05-01')\n",
        "#יצירת נתוני הוולידציה רק על ינואר-אפריל 2011\n",
        "val_time_split = df_train_processed[validation_mask].copy()\n",
        "\n",
        "\n",
        "X_train_time = train_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_train_time_residual = train_time_split['SalePrice_Residual']\n",
        "X_val_time = val_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_val_actual_price = val_time_split['SalePrice_adj']\n",
        "val_time_trend = df_train_raw.loc[val_time_split.index, 'SalePrice_Trend'].values\n",
        "\n",
        "#target coding\n",
        "#חישוב מחיר חציוני למחיר למדינה בלי זליגת מידע\n",
        "median_price_by_state = train_time_split.groupby('state')['SalePrice_adj'].median()\n",
        "X_train_time['State_Median_Price'] = X_train_time['state'].map(median_price_by_state)\n",
        "X_val_time['State_Median_Price'] = X_val_time['state'].map(median_price_by_state)\n",
        "global_median_price = train_time_split['SalePrice_adj'].median()\n",
        "X_train_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "X_val_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "#חישוב מחיר חציוני לנמחיר למודל ולמוכר בלי זליגת מידע\n",
        "fimodel_median_price = train_time_split.groupby('fiModelDesc')['SalePrice_adj'].median()\n",
        "auctioneer_median_price = train_time_split.groupby('auctioneerID')['SalePrice_adj'].median()\n",
        "\n",
        "\n",
        "X_train_time['fiModelDesc_target_encoded'] = X_train_time['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_train_time['auctioneerID_target_encoded'] = X_train_time['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "X_val_time['fiModelDesc_target_encoded'] = X_val_time['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_val_time['auctioneerID_target_encoded'] = X_val_time['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "\n",
        "\n",
        "X_val_time = X_val_time[X_train_time.columns]\n",
        "\n",
        "# 3.4 אימון מודל וולידציה\n",
        "print(\"\\nמאמן מודל וולידציה (על נתוני 2000-2010)...\")\n",
        "\n",
        "#פרמטרים האידיאליים שנמצאו בחיפוש\n",
        "user_params = {\n",
        "    'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 4,\n",
        "    'min_samples_leaf': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 42\n",
        "}\n",
        "\n",
        "\n",
        "validation_model = RandomForestRegressor(**user_params)\n",
        "validation_model.fit(X_train_time, y_train_time_residual)\n",
        "\n",
        "#  חיזוי וחישוב ציוני טעות\n",
        "initial_val_preds_residual = validation_model.predict(X_val_time)\n",
        "initial_val_preds_full_price = val_time_trend + initial_val_preds_residual\n",
        "\n",
        "def rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "def rmsle(y_true, y_pred): return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 1)))\n",
        "\n",
        "final_val_rmse = rmse(y_val_actual_price, initial_val_preds_full_price)\n",
        "final_val_rmsle = rmsle(y_val_actual_price, initial_val_preds_full_price)\n",
        "\n",
        "print(\"\\n--- ביצועי המודל על סט הוולידציה העונתי ---\")\n",
        "print(f\"סט וולידציה (Validation Set - ינואר-אפריל 2011):\")\n",
        "print(f\"\\tRMSE:  ${final_val_rmse:,.2f}\")\n",
        "print(f\"\\tRMSLE: {final_val_rmsle:.4f}\\n\")\n",
        "\n",
        "\n",
        "# ---  אימון מודל סופי  ---\n",
        "#המודל הזה כולל גם את 2011\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"---  מאמן מודל סופי עם הפרמטרים ---\")\n",
        "\n",
        "# 4.1 הכנת הנתונים הסופיים לאימון\n",
        "X_full_train = df_train_processed.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_full_train_residual = df_train_processed['SalePrice_Residual']\n",
        "df_valid_processed = df_combined[df_combined['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "df_valid_processed_aligned = df_valid_processed[X_full_train.columns]\n",
        "\n",
        "# 4.2 Target Encoding לכל סט האימון ולסט המבחן\n",
        "X_full_train['State_Median_Price'] = X_full_train['state'].map(median_price_by_state)\n",
        "X_full_train['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "df_valid_processed_aligned['State_Median_Price'] = df_valid_processed_aligned['state'].map(median_price_by_state)\n",
        "df_valid_processed_aligned['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "df_valid_processed_aligned = df_valid_processed_aligned[X_full_train.columns]\n",
        "\n",
        "\n",
        "X_full_train['fiModelDesc_target_encoded'] = X_full_train['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_full_train['auctioneerID_target_encoded'] = X_full_train['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "df_valid_processed_aligned['fiModelDesc_target_encoded'] = df_valid_processed_aligned['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "df_valid_processed_aligned['auctioneerID_target_encoded'] = df_valid_processed_aligned['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "# 4.3 אימון המודל הסופי\n",
        "final_model = RandomForestRegressor(**user_params)\n",
        "final_model.fit(X_full_train, y_full_train_residual)\n",
        "print(\"אימון המודל הסופי הושלם!\")\n",
        "\n",
        "# ---  יצירת קובץ הגשה סופי ---\n",
        "\n",
        "final_residuals_pred = final_model.predict(df_valid_processed_aligned)\n",
        "final_trend_values = df_valid_raw['SalePrice_Trend'].values\n",
        "#המודל מחזיר שאלית ולכן צריך להפוך חזרה למחיר על פי מודל הרגרסיה\n",
        "final_price_pred = final_trend_values + final_residuals_pred\n",
        "final_price_pred_floored = np.maximum(final_price_pred, 1000)\n",
        "\n",
        "df_submission = pd.DataFrame({'SalesID': df_valid_raw['SalesID'], 'SalePrice': final_price_pred_floored})\n",
        "submission_filename = f'{DRIVE_PATH}submission_Final_Winning_Model_v4.csv'\n",
        "df_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nקובץ ההגשה '{submission_filename}' נשמר בהצלחה!\")\n",
        "print(\"5 השורות הראשונות בקובץ ההגשה:\")\n",
        "print(df_submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- שלב 3.6: חישוב Permutation Importance ---\n",
        "print(\"\\n\" + \"-\"*20 + \"  : מחשב Permutation Importance \" + \"-\"*20)\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# הרצת החישוב על מודל הוולידציה וסט הוולידציה\n",
        "result = permutation_importance(\n",
        "    validation_model,\n",
        "    X_val_time,\n",
        "    y_val_actual_price,\n",
        "    n_repeats=10,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "# יצירת DataFrame להצגת התוצאות בצורה נוחה\n",
        "perm_importance_df = pd.DataFrame({\n",
        "    'feature': X_val_time.columns,\n",
        "    'importance_mean': result.importances_mean,\n",
        "}).sort_values('importance_mean', ascending=False)\n",
        "\n",
        "print(\"\\n--- Top 20 Features (הכי חשובים) לפי Permutation Importance ---\")\n",
        "print(perm_importance_df.head(20).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Bottom 10 Features (הכי פחות חשובים או מזיקים) ---\")\n",
        "print(perm_importance_df.tail(10).to_string(index=False))\n",
        "\n",
        "# זיהוי פיצ'רים עם חשיבות שלילית (כאלה שכנראה מזיקים למודל)\n",
        "harmful_features = perm_importance_df[perm_importance_df['importance_mean'] < 0]\n",
        "if not harmful_features.empty:\n",
        "    print(\"\\n פיצ'רים עם חשיבות שלילית :\")\n",
        "    print(harmful_features.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n לא נמצאו פיצ'רים עם חשיבות שלילית מובהקת.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Rzh97dYBoG",
        "outputId": "e396adef-3c05-4af6-9cc2-31e5cba877c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------- שלב 3.6: מחשב Permutation Importance --------------------\n",
            "בודק אילו פיצ'רים הכי משפיעים על ביצועי המודל על סט הוולידציה...\n",
            "\n",
            "--- Top 20 Features (הכי חשובים) לפי Permutation Importance ---\n",
            "                   feature  importance_mean\n",
            "fiModelDesc_target_encoded         0.437407\n",
            "               ProductSize         0.095260\n",
            "               fiModelDesc         0.050992\n",
            "               fiBaseModel         0.039620\n",
            "                  YearMade         0.030780\n",
            "           fiSecondaryDesc         0.028884\n",
            "        fiProductClassDesc         0.023597\n",
            "            Grouser_Tracks         0.023198\n",
            "           Hydraulics_Flow         0.020779\n",
            "         fiModelDescriptor         0.017619\n",
            "            Coupler_System         0.016045\n",
            "            Enclosure_Type         0.015254\n",
            "                     Forks         0.012466\n",
            "                has_Ripper         0.011239\n",
            "              Drive_System         0.010457\n",
            "           Blade_Extension         0.009712\n",
            "               Blade_Width         0.008273\n",
            "                 Tire_Size         0.006887\n",
            "                 is_loader         0.005796\n",
            "                   ModelID         0.005434\n",
            "\n",
            "--- Bottom 10 Features (הכי פחות חשובים או מזיקים) ---\n",
            "                 feature  importance_mean\n",
            "        Backhoe_Mounting        -0.001958\n",
            "            is_excavator        -0.002986\n",
            "                Pad_Type        -0.003064\n",
            "         Pattern_Changer        -0.004696\n",
            "              Blade_Type        -0.005206\n",
            "                is_track        -0.005610\n",
            "            Grouser_Type        -0.006642\n",
            "            Ride_Control        -0.012935\n",
            "              Hydraulics        -0.013453\n",
            "MachineHoursCurrentMeter        -0.019720\n",
            "\n",
            "🚨 פיצ'רים עם חשיבות שלילית (מועמדים להסרה):\n",
            "                    feature  importance_mean\n",
            "          Engine_Horsepower        -0.000093\n",
            "                  DayOfYear        -0.000502\n",
            "    Undercarriage_Pad_Width        -0.000850\n",
            "                      Thumb        -0.000860\n",
            "                 Track_Type        -0.000862\n",
            "                   is_dozer        -0.000903\n",
            "               auctioneerID        -0.001057\n",
            "               Stick_Length        -0.001433\n",
            "auctioneerID_target_encoded        -0.001484\n",
            "                  UsageBand        -0.001802\n",
            "           Backhoe_Mounting        -0.001958\n",
            "               is_excavator        -0.002986\n",
            "                   Pad_Type        -0.003064\n",
            "            Pattern_Changer        -0.004696\n",
            "                 Blade_Type        -0.005206\n",
            "                   is_track        -0.005610\n",
            "               Grouser_Type        -0.006642\n",
            "               Ride_Control        -0.012935\n",
            "                 Hydraulics        -0.013453\n",
            "   MachineHoursCurrentMeter        -0.019720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "# להוסיף בסוף הקוד, אחרי שהמודל הסופי אומן\n",
        "print(\"\\n--- שלב 6: SHAP Analysis ---\")\n",
        "\n",
        "import shap\n",
        "\n",
        "# מדגם קטן לSHAP - 1000-2000 שורות מספיקות\n",
        "sample_size = min(1000, len(X_full_train))\n",
        "X_sample = X_full_train.sample(n=sample_size, random_state=42)\n",
        "\n",
        "print(f\"מריץ SHAP על מדגם של {sample_size} שורות...\")\n",
        "\n",
        "# יצירת explainer\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "# חישוב חשיבות features\n",
        "feature_importance = np.abs(shap_values).mean(0)\n",
        "feature_names = X_sample.columns\n",
        "\n",
        "# יצירת DataFrame עם החשיבות\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 Features החשובים ביותר:\")\n",
        "print(importance_df.head(15).to_string(index=False))\n",
        "\n",
        "print(f\"\\nBottom 10 Features עם החשיבות הנמוכה ביותר:\")\n",
        "print(importance_df.tail(10).to_string(index=False))\n",
        "\n",
        "# זיהוי features עם חשיבות נמוכה מאוד\n",
        "low_threshold = np.percentile(feature_importance, 10)  # 10% הנמוכים ביותר\n",
        "low_impact_features = importance_df[importance_df['importance'] < low_threshold]['feature'].tolist()\n",
        "\n",
        "print(f\"\\nFeatures עם חשיבות נמוכה שאפשר לשקול להסיר:\")\n",
        "for feature in low_impact_features:\n",
        "    print(f\"  - {feature}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "qCYIsxRdu0Hn",
        "outputId": "00e51e00-214e-490c-9dba-56e20b85950e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_drv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-571399783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install shap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# להוסיף בסוף הקוד, אחרי שהמודל הסופי אומן\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- שלב 6: SHAP Analysis ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}