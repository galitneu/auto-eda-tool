{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwhsEc2iokVWqjKJXOtFXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galitneu/auto-eda-tool/blob/main/8799.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCGR13MYiEHW",
        "outputId": "45b62d0f-055d-4012-aad1-51aab1d4ebf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 砖 1: 注 转 ---\n",
            "Mounted at /content/drive\n",
            "转 注 爪.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:113: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:118: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_combined['MachineHoursCurrentMeter'].fillna(df_combined['MachineHoursCurrentMeter'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "---  注专转 爪注 注 住 爪 注转 (专-驻专 2011) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:178: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:179: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_val_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  爪 (注 转 2000-2010)...\n",
            "\n",
            "--- 爪注  注 住 爪 注转 ---\n",
            "住 爪 (Validation Set - 专-驻专 2011):\n",
            "\tRMSE:  $8,672.77\n",
            "\tRMSLE: 0.2207\n",
            "\n",
            "\n",
            "==================================================\n",
            "---    住驻 注 驻专专 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1138722705.py:239: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_full_train['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
            "/tmp/ipython-input-1138722705.py:242: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_valid_processed_aligned['State_Median_Price'].fillna(global_median_price, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  住驻 砖!\n",
            "\n",
            "拽抓 砖 '/content/drive/MyDrive/KaggleProject/submission_Final_Winning_Model_v4.csv' 砖专 爪!\n",
            "5 砖专转 专砖转 拽抓 砖:\n",
            "        SalesID     SalePrice\n",
            "313947  1222837  55901.228088\n",
            "313948  1222839  79930.670615\n",
            "313949  1222841  33336.578450\n",
            "313950  1222843  16935.470268\n",
            "313951  1222845  40982.306060\n"
          ]
        }
      ],
      "source": [
        "# --- 砖 0:   住驻专转 专砖转 ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 砖 1: 专转 注转 转 ---\n",
        "print(\"--- 砖 1: 注 转 ---\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_PATH = '/content/drive/MyDrive/KaggleProject/'\n",
        "\n",
        "# 转转 拽爪  \n",
        "try:\n",
        "    df_train_raw = pd.read_csv(f'{DRIVE_PATH}Train.csv', low_memory=False, parse_dates=['saledate'])\n",
        "    df_valid_raw = pd.read_csv(f'{DRIVE_PATH}Valid.csv', low_memory=False, parse_dates=['saledate'])\n",
        "    print(\"转 注 爪.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"砖:  砖拽爪 'Train.csv' -'Valid.csv' 爪 转拽: {DRIVE_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# ---  注 转 住转 驻 ---\n",
        "\n",
        "# 住 砖 2000 注  砖 砖转 砖 砖 转转 砖   专注砖\n",
        "df_train_raw = df_train_raw[df_train_raw['saledate'].dt.year >= 2000].copy()\n",
        "df_valid_raw = df_valid_raw[df_valid_raw['saledate'].dt.year >= 2000].copy()\n",
        "\n",
        "#转拽 专 砖转 2012  驻爪\n",
        "cpi_data_real = {\n",
        "    2000: 172.2, 2001: 177.1, 2002: 179.9, 2003: 184.0, 2004: 188.9, 2005: 195.3,\n",
        "    2006: 201.6, 2007: 207.3, 2008: 215.3, 2009: 214.5, 2010: 218.1, 2011: 224.9, 2012: 229.6\n",
        "}\n",
        "ADJUSTMENT_YEAR = 2012\n",
        "inflation_multiplier = {year: cpi_data_real[ADJUSTMENT_YEAR] / cpi for year, cpi in cpi_data_real.items()}\n",
        "\n",
        "#爪专转 注 砖 专 转拽\n",
        "df_train_raw['SalePrice_adj'] = df_train_raw.apply(lambda row: row['SalePrice'] * inflation_multiplier.get(row['saledate'].year, 1), axis=1)\n",
        "train_original_prices = df_train_raw[['SalePrice', 'SalePrice_adj']].copy()\n",
        "\n",
        "#爪专转 注   转 驻 专 砖 \n",
        "df_train_raw['source'] = 'train'\n",
        "df_valid_raw['source'] = 'valid'\n",
        "df_combined_temp = pd.concat([df_train_raw.drop(['SalePrice', 'SalePrice_adj'], axis=1), df_valid_raw], ignore_index=True)\n",
        "\n",
        "#驻砖 专 转专 拽 转专  爪 转 住驻专  砖注专 注专   专\n",
        "min_date = df_combined_temp['saledate'].min()\n",
        "#驻爪 转专 专 拽 砖  砖, 砖,  转 砖,   专 砖 转专\n",
        "for df in [df_combined_temp]:\n",
        "    df['saleYear'] = df['saledate'].dt.year\n",
        "    df['saleMonth'] = df['saledate'].dt.month\n",
        "    df['DayOfYear'] = df['saledate'].dt.dayofyear\n",
        "    df['DaysFromStart'] = (df['saledate'] - min_date).dt.days\n",
        "\n",
        "#驻爪 砖 住 砖  \n",
        "df_train_raw = df_combined_temp[df_combined_temp['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_valid_raw = df_combined_temp[df_combined_temp['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "df_train_raw = pd.concat([df_train_raw.reset_index(drop=True), train_original_prices.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# 2.2 砖  砖专转 注 砖  注转\n",
        "#驻爪 转 砖  砖 专-驻专  砖专\n",
        "early_season_train_df = df_train_raw[df_train_raw['saleMonth'].isin([1, 2, 3, 4])].copy()\n",
        "rest_of_year_train_df = df_train_raw[~df_train_raw['saleMonth'].isin([1, 2, 3, 4])].copy()\n",
        "\n",
        "#爪专转  专专住   拽 \n",
        "trend_model_early = LinearRegression()\n",
        "trend_model_early.fit(early_season_train_df[['DaysFromStart']], early_season_train_df['SalePrice_adj'])\n",
        "trend_model_rest = LinearRegression()\n",
        "trend_model_rest.fit(rest_of_year_train_df[['DaysFromStart']], rest_of_year_train_df['SalePrice_adj'])\n",
        "\n",
        "#专转 驻爪专 注专 砖 专 砖 专 转 注 驻 专专住\n",
        "def predict_seasonal_trend(df):\n",
        "    early_mask = df['saleMonth'].isin([1, 2, 3, 4])\n",
        "    predictions = pd.Series(index=df.index, dtype=float)\n",
        "    if early_mask.sum() > 0:\n",
        "        predictions.loc[early_mask] = trend_model_early.predict(df.loc[early_mask, ['DaysFromStart']])\n",
        "    if (~early_mask).sum() > 0:\n",
        "        predictions.loc[~early_mask] = trend_model_rest.predict(df.loc[~early_mask, ['DaysFromStart']])\n",
        "    return predictions\n",
        "\n",
        "#注专  砖专 - 砖 专 砖 专 转\n",
        "df_train_raw['SalePrice_Trend'] = predict_seasonal_trend(df_train_raw)\n",
        "df_valid_raw['SalePrice_Trend'] = predict_seasonal_trend(df_valid_raw)\n",
        "#砖 驻注专 砖 专 砖 注专 转  专 驻注  砖注 转 .  专拽 注专 砖 2000-2010\n",
        "df_train_raw['SalePrice_Residual'] = df_train_raw['SalePrice_adj'] - df_train_raw['SalePrice_Trend']\n",
        "\n",
        "# 2.3  注 住驻\n",
        "train_labels_residual = df_train_raw['SalePrice_Residual'].copy()\n",
        "df_train_proc = df_train_raw.drop(['SalePrice', 'SalePrice_adj', 'SalePrice_Trend', 'SalePrice_Residual', 'saledate', 'SalesID', 'MachineID'], axis=1)\n",
        "df_train_proc['source'] = 'train'\n",
        "df_valid_proc = df_valid_raw.drop(['SalePrice_Trend', 'saledate', 'SalesID', 'MachineID'], axis=1)\n",
        "df_valid_proc['source'] = 'valid'\n",
        "df_combined = pd.concat([df_train_proc, df_valid_proc], ignore_index=True, sort=False)\n",
        "\n",
        "# ---  住转 驻 注 转   ---\n",
        "\n",
        "#专转  注专 砖转 砖 砖转 爪专  转拽\n",
        "df_combined['is_YearMade_1000'] = (df_combined['YearMade'] == 1000).astype(int)\n",
        "\n",
        "# 转拽 砖转 砖 砖转 爪专 砖 1000\n",
        "year_made_by_model = df_combined.groupby('fiModelDesc')['YearMade'].median().astype(int)\n",
        "rows_to_fix_idx = df_combined[df_combined['YearMade'] == 1000].index\n",
        "#住转  爪 砖  住驻爪驻\n",
        "imputed_years = df_combined.loc[rows_to_fix_idx, 'fiModelDesc'].map(year_made_by_model)\n",
        "global_median_year = df_combined.loc[df_combined['YearMade'] != 1000, 'YearMade'].median()\n",
        "#住转\n",
        "imputed_years = imputed_years.fillna(global_median_year)\n",
        "df_combined.loc[rows_to_fix_idx, 'YearMade'] = imputed_years.values\n",
        "#砖   专\n",
        "df_combined['machineAge'] = df_combined['saleYear'] - df_combined['YearMade']\n",
        "\n",
        "#专转  注转 砖注转 注  转拽转\n",
        "df_combined['MachineHoursCurrentMeter'].replace(0, np.nan, inplace=True)\n",
        "#砖 爪 砖 砖注转 注  住驻爪驻\n",
        "imputed_hours = df_combined.groupby('fiModelDesc')['MachineHoursCurrentMeter'].transform(lambda x: x.fillna(x.median()))\n",
        "df_combined['MachineHoursCurrentMeter'] = imputed_hours\n",
        "if df_combined['MachineHoursCurrentMeter'].isnull().sum() > 0:\n",
        "    df_combined['MachineHoursCurrentMeter'].fillna(df_combined['MachineHoursCurrentMeter'].median(), inplace=True)\n",
        "\n",
        "# 驻 -auctioneerID  专拽  拽  爪\n",
        "if df_combined['auctioneerID'].isnull().sum() > 0:\n",
        "    df_combined['auctioneerID_is_missing'] = df_combined['auctioneerID'].isnull()\n",
        "    df_combined['auctioneerID'] = df_combined['auctioneerID'].fillna(df_combined['auctioneerID'].median())\n",
        "\n",
        "# --- 住驻转 驻 Ripper -Enclosure\n",
        "df_combined['Ripper_is_missing'] = df_combined['Ripper'].isnull().astype(int)\n",
        "ripper_types = ['Yes', 'Multi Shank', 'Single Shank']\n",
        "df_combined['has_Ripper'] = df_combined['Ripper'].isin(ripper_types).astype(int)\n",
        "enclosure_mode = df_combined['Enclosure'].mode()[0]\n",
        "df_combined['Enclosure_Type'] = df_combined['Enclosure'].fillna(enclosure_mode).astype('category').cat.codes\n",
        "df_combined.drop(['Ripper', 'Enclosure'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "df_combined['fiProductClassDesc'] = df_combined['fiProductClassDesc'].fillna('')\n",
        "keywords_to_extract = ['excavator', 'dozer', 'loader', 'crawler', 'wheel', 'track']\n",
        "for keyword in keywords_to_extract:\n",
        "    df_combined[f'is_{keyword}'] = df_combined['fiProductClassDesc'].str.contains(keyword, case=False).astype(int)\n",
        "df_combined['is_Hours_Zero'] = (df_combined['MachineHoursCurrentMeter'] == 0).astype(int)\n",
        "df_combined['is_ProductGroup_5'] = (df_combined['ProductGroup'] == 5).astype(int)\n",
        "df_combined['is_ProductGroup_2'] = (df_combined['ProductGroup'] == 2).astype(int)\n",
        "\n",
        "# 专转 砖专 注转 拽住 拽 住驻专\n",
        "source_col = df_combined['source']\n",
        "df_combined = df_combined.drop('source', axis=1)\n",
        "for col_name in df_combined.columns:\n",
        "    if pd.api.types.is_object_dtype(df_combined[col_name]):\n",
        "        df_combined[col_name] = df_combined[col_name].fillna('missing').astype('category').cat.codes\n",
        "df_combined['source'] = source_col\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"---  注专转 爪注 注 住 爪 注转 (专-驻专 2011) ---\")\n",
        "\n",
        "#  转 转 驻爪\n",
        "df_train_processed = df_combined[df_combined['source'] == 'train'].drop('source', axis=1).copy()\n",
        "df_train_processed['SalePrice_Residual'] = train_labels_residual.values\n",
        "df_train_processed['SalePrice_adj'] = df_train_raw['SalePrice_adj'].values\n",
        "df_train_processed['saledate'] = df_train_raw['saledate']\n",
        "\n",
        "#  驻爪 注转\n",
        "train_time_split = df_train_processed[df_train_processed['saledate'] < '2011-01-01'].copy()\n",
        "validation_mask = (df_train_processed['saledate'] >= '2011-01-01') & (df_train_processed['saledate'] < '2011-05-01')\n",
        "#爪专转 转 爪 专拽 注 专-驻专 2011\n",
        "val_time_split = df_train_processed[validation_mask].copy()\n",
        "\n",
        "\n",
        "X_train_time = train_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_train_time_residual = train_time_split['SalePrice_Residual']\n",
        "X_val_time = val_time_split.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_val_actual_price = val_time_split['SalePrice_adj']\n",
        "val_time_trend = df_train_raw.loc[val_time_split.index, 'SalePrice_Trend'].values\n",
        "\n",
        "#target coding\n",
        "#砖 专 爪 专   转 注\n",
        "median_price_by_state = train_time_split.groupby('state')['SalePrice_adj'].median()\n",
        "X_train_time['State_Median_Price'] = X_train_time['state'].map(median_price_by_state)\n",
        "X_val_time['State_Median_Price'] = X_val_time['state'].map(median_price_by_state)\n",
        "global_median_price = train_time_split['SalePrice_adj'].median()\n",
        "X_train_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "X_val_time['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "#砖 专 爪 专  专  转 注\n",
        "fimodel_median_price = train_time_split.groupby('fiModelDesc')['SalePrice_adj'].median()\n",
        "auctioneer_median_price = train_time_split.groupby('auctioneerID')['SalePrice_adj'].median()\n",
        "\n",
        "\n",
        "X_train_time['fiModelDesc_target_encoded'] = X_train_time['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_train_time['auctioneerID_target_encoded'] = X_train_time['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "X_val_time['fiModelDesc_target_encoded'] = X_val_time['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_val_time['auctioneerID_target_encoded'] = X_val_time['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "\n",
        "\n",
        "X_val_time = X_val_time[X_train_time.columns]\n",
        "\n",
        "# 3.4   爪\n",
        "print(\"\\n  爪 (注 转 2000-2010)...\")\n",
        "\n",
        "#驻专专  砖爪 驻砖\n",
        "user_params = {\n",
        "    'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 4,\n",
        "    'min_samples_leaf': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 42\n",
        "}\n",
        "\n",
        "\n",
        "validation_model = RandomForestRegressor(**user_params)\n",
        "validation_model.fit(X_train_time, y_train_time_residual)\n",
        "\n",
        "#   砖 爪 注转\n",
        "initial_val_preds_residual = validation_model.predict(X_val_time)\n",
        "initial_val_preds_full_price = val_time_trend + initial_val_preds_residual\n",
        "\n",
        "def rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "def rmsle(y_true, y_pred): return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 1)))\n",
        "\n",
        "final_val_rmse = rmse(y_val_actual_price, initial_val_preds_full_price)\n",
        "final_val_rmsle = rmsle(y_val_actual_price, initial_val_preds_full_price)\n",
        "\n",
        "print(\"\\n--- 爪注  注 住 爪 注转 ---\")\n",
        "print(f\"住 爪 (Validation Set - 专-驻专 2011):\")\n",
        "print(f\"\\tRMSE:  ${final_val_rmse:,.2f}\")\n",
        "print(f\"\\tRMSLE: {final_val_rmsle:.4f}\\n\")\n",
        "\n",
        "\n",
        "# ---    住驻  ---\n",
        "#    转 2011\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"---    住驻 注 驻专专 ---\")\n",
        "\n",
        "# 4.1 转 转 住驻 \n",
        "X_full_train = df_train_processed.drop(['SalePrice_Residual', 'SalePrice_adj', 'saledate'], axis=1)\n",
        "y_full_train_residual = df_train_processed['SalePrice_Residual']\n",
        "df_valid_processed = df_combined[df_combined['source'] == 'valid'].drop('source', axis=1).copy()\n",
        "df_valid_processed_aligned = df_valid_processed[X_full_train.columns]\n",
        "\n",
        "# 4.2 Target Encoding  住  住 \n",
        "X_full_train['State_Median_Price'] = X_full_train['state'].map(median_price_by_state)\n",
        "X_full_train['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "df_valid_processed_aligned['State_Median_Price'] = df_valid_processed_aligned['state'].map(median_price_by_state)\n",
        "df_valid_processed_aligned['State_Median_Price'].fillna(global_median_price, inplace=True)\n",
        "\n",
        "df_valid_processed_aligned = df_valid_processed_aligned[X_full_train.columns]\n",
        "\n",
        "\n",
        "X_full_train['fiModelDesc_target_encoded'] = X_full_train['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "X_full_train['auctioneerID_target_encoded'] = X_full_train['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "df_valid_processed_aligned['fiModelDesc_target_encoded'] = df_valid_processed_aligned['fiModelDesc'].map(fimodel_median_price).fillna(global_median_price)\n",
        "df_valid_processed_aligned['auctioneerID_target_encoded'] = df_valid_processed_aligned['auctioneerID'].map(auctioneer_median_price).fillna(global_median_price)\n",
        "\n",
        "# 4.3   住驻\n",
        "final_model = RandomForestRegressor(**user_params)\n",
        "final_model.fit(X_full_train, y_full_train_residual)\n",
        "print(\"  住驻 砖!\")\n",
        "\n",
        "# ---  爪专转 拽抓 砖 住驻 ---\n",
        "\n",
        "final_residuals_pred = final_model.predict(df_valid_processed_aligned)\n",
        "final_trend_values = df_valid_raw['SalePrice_Trend'].values\n",
        "# 专 砖转  爪专 驻 专 专 注 驻  专专住\n",
        "final_price_pred = final_trend_values + final_residuals_pred\n",
        "final_price_pred_floored = np.maximum(final_price_pred, 1000)\n",
        "\n",
        "df_submission = pd.DataFrame({'SalesID': df_valid_raw['SalesID'], 'SalePrice': final_price_pred_floored})\n",
        "submission_filename = f'{DRIVE_PATH}submission_Final_Winning_Model_v4.csv'\n",
        "df_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\n拽抓 砖 '{submission_filename}' 砖专 爪!\")\n",
        "print(\"5 砖专转 专砖转 拽抓 砖:\")\n",
        "print(df_submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 砖 3.6: 砖 Permutation Importance ---\n",
        "print(\"\\n\" + \"-\"*20 + \"  : 砖 Permutation Importance \" + \"-\"*20)\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# 专爪转 砖 注  爪 住 爪\n",
        "result = permutation_importance(\n",
        "    validation_model,\n",
        "    X_val_time,\n",
        "    y_val_actual_price,\n",
        "    n_repeats=10,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "# 爪专转 DataFrame 爪转 转爪转 爪专 \n",
        "perm_importance_df = pd.DataFrame({\n",
        "    'feature': X_val_time.columns,\n",
        "    'importance_mean': result.importances_mean,\n",
        "}).sort_values('importance_mean', ascending=False)\n",
        "\n",
        "print(\"\\n--- Top 20 Features ( 砖) 驻 Permutation Importance ---\")\n",
        "print(perm_importance_df.head(20).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Bottom 10 Features ( 驻转 砖  拽) ---\")\n",
        "print(perm_importance_df.tail(10).to_string(index=False))\n",
        "\n",
        "#  驻爪'专 注 砖转 砖转 ( 砖专 拽 )\n",
        "harmful_features = perm_importance_df[perm_importance_df['importance_mean'] < 0]\n",
        "if not harmful_features.empty:\n",
        "    print(\"\\n 驻爪'专 注 砖转 砖转 :\")\n",
        "    print(harmful_features.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n  爪 驻爪'专 注 砖转 砖转 拽转.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Rzh97dYBoG",
        "outputId": "e396adef-3c05-4af6-9cc2-31e5cba877c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------- 砖 3.6: 砖 Permutation Importance --------------------\n",
            "拽  驻爪'专  砖驻注 注 爪注  注 住 爪...\n",
            "\n",
            "--- Top 20 Features ( 砖) 驻 Permutation Importance ---\n",
            "                   feature  importance_mean\n",
            "fiModelDesc_target_encoded         0.437407\n",
            "               ProductSize         0.095260\n",
            "               fiModelDesc         0.050992\n",
            "               fiBaseModel         0.039620\n",
            "                  YearMade         0.030780\n",
            "           fiSecondaryDesc         0.028884\n",
            "        fiProductClassDesc         0.023597\n",
            "            Grouser_Tracks         0.023198\n",
            "           Hydraulics_Flow         0.020779\n",
            "         fiModelDescriptor         0.017619\n",
            "            Coupler_System         0.016045\n",
            "            Enclosure_Type         0.015254\n",
            "                     Forks         0.012466\n",
            "                has_Ripper         0.011239\n",
            "              Drive_System         0.010457\n",
            "           Blade_Extension         0.009712\n",
            "               Blade_Width         0.008273\n",
            "                 Tire_Size         0.006887\n",
            "                 is_loader         0.005796\n",
            "                   ModelID         0.005434\n",
            "\n",
            "--- Bottom 10 Features ( 驻转 砖  拽) ---\n",
            "                 feature  importance_mean\n",
            "        Backhoe_Mounting        -0.001958\n",
            "            is_excavator        -0.002986\n",
            "                Pad_Type        -0.003064\n",
            "         Pattern_Changer        -0.004696\n",
            "              Blade_Type        -0.005206\n",
            "                is_track        -0.005610\n",
            "            Grouser_Type        -0.006642\n",
            "            Ride_Control        -0.012935\n",
            "              Hydraulics        -0.013453\n",
            "MachineHoursCurrentMeter        -0.019720\n",
            "\n",
            " 驻爪'专 注 砖转 砖转 (注 住专):\n",
            "                    feature  importance_mean\n",
            "          Engine_Horsepower        -0.000093\n",
            "                  DayOfYear        -0.000502\n",
            "    Undercarriage_Pad_Width        -0.000850\n",
            "                      Thumb        -0.000860\n",
            "                 Track_Type        -0.000862\n",
            "                   is_dozer        -0.000903\n",
            "               auctioneerID        -0.001057\n",
            "               Stick_Length        -0.001433\n",
            "auctioneerID_target_encoded        -0.001484\n",
            "                  UsageBand        -0.001802\n",
            "           Backhoe_Mounting        -0.001958\n",
            "               is_excavator        -0.002986\n",
            "                   Pad_Type        -0.003064\n",
            "            Pattern_Changer        -0.004696\n",
            "                 Blade_Type        -0.005206\n",
            "                   is_track        -0.005610\n",
            "               Grouser_Type        -0.006642\n",
            "               Ride_Control        -0.012935\n",
            "                 Hydraulics        -0.013453\n",
            "   MachineHoursCurrentMeter        -0.019720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "# 住祝 住祝 拽, 专 砖 住驻 \n",
        "print(\"\\n--- 砖 6: SHAP Analysis ---\")\n",
        "\n",
        "import shap\n",
        "\n",
        "#  拽 SHAP - 1000-2000 砖专转 住驻拽转\n",
        "sample_size = min(1000, len(X_full_train))\n",
        "X_sample = X_full_train.sample(n=sample_size, random_state=42)\n",
        "\n",
        "print(f\"专抓 SHAP 注  砖 {sample_size} 砖专转...\")\n",
        "\n",
        "# 爪专转 explainer\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "# 砖 砖转 features\n",
        "feature_importance = np.abs(shap_values).mean(0)\n",
        "feature_names = X_sample.columns\n",
        "\n",
        "# 爪专转 DataFrame 注 砖转\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 Features 砖 转专:\")\n",
        "print(importance_df.head(15).to_string(index=False))\n",
        "\n",
        "print(f\"\\nBottom 10 Features 注 砖转  转专:\")\n",
        "print(importance_df.tail(10).to_string(index=False))\n",
        "\n",
        "#  features 注 砖转  \n",
        "low_threshold = np.percentile(feature_importance, 10)  # 10%  转专\n",
        "low_impact_features = importance_df[importance_df['importance'] < low_threshold]['feature'].tolist()\n",
        "\n",
        "print(f\"\\nFeatures 注 砖转  砖驻砖专 砖拽 住专:\")\n",
        "for feature in low_impact_features:\n",
        "    print(f\"  - {feature}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "qCYIsxRdu0Hn",
        "outputId": "00e51e00-214e-490c-9dba-56e20b85950e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_drv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-571399783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install shap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 住祝 住祝 拽, 专 砖 住驻 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- 砖 6: SHAP Analysis ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}